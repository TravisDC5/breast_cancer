{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data\n",
    "from htru1 import HTRU1\n",
    "\n",
    "#Transforms the data. This seems like a required step as I kepts getting errors if I did not include it\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(), # randomly flip and rotate\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "#Specifically import the training data and test data\n",
    "train_data = HTRU1('data', train=True, download=True, transform=transform)\n",
    "test_data = HTRU1('data', train=False, download=True, transform=transform)\n",
    "\n",
    "#Variable setup to extract the data\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=50000, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=10000, shuffle=True, num_workers=2)\n",
    "\n",
    "#Extracts the data into the features and the labels\n",
    "dataiter = iter(trainloader)\n",
    "train_tensor_images, train_tensor_labels = dataiter.next()\n",
    "dataiter = iter(testloader)\n",
    "test_tensor_images, test_tensor_labels = dataiter.next()\n",
    "\n",
    "#Converts the data to np arrays (found them easier to work with)\n",
    "train_features = np.array(train_tensor_images)\n",
    "train_label = np.array(train_tensor_labels)\n",
    "test_features = np.array(test_tensor_images)\n",
    "test_label = np.array(test_tensor_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformed the feates from (5000, 3, 32, 32) into (3, 5000, 32, 32)\n",
    "train_features_t = np.transpose(train_features, (1,0,2,3))\n",
    "test_features_t = np.transpose(test_features, (1,0,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning each layer into their own variable\n",
    "train_layer1 = train_features_t[0]\n",
    "train_layer2 = train_features_t[1]\n",
    "train_layer3 = train_features_t[2]\n",
    "test_layer1 = test_features_t[0]\n",
    "test_layer2 = test_features_t[1]\n",
    "test_layer3 = test_features_t[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattening the data\n",
    "ndims = train_layer1.shape[1] * train_layer1.shape[2]\n",
    "X_train = train_layer1.reshape(train_layer1.shape[0],ndims)\n",
    "X_test = test_layer1.reshape(test_layer1.shape[0],ndims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = train_layer1.reshape(train_layer2.shape[0],ndims)\n",
    "X_test_2 = test_layer1.reshape(test_layer2.shape[0],ndims)\n",
    "\n",
    "X_train_3 = train_layer1.reshape(train_layer3.shape[0],ndims)\n",
    "X_test_3 = test_layer1.reshape(test_layer3.shape[0],ndims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the y data\n",
    "y_train = train_label\n",
    "y_test  = test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model,metric):\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[metric])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model,epochs):\n",
    "    model.fit(\n",
    "    X_train_3,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(metric,epoch):\n",
    "    built_model = build_model()\n",
    "    compiled_model = compile_model(built_model,metric)\n",
    "    model = fit_model(compiled_model,epoch)\n",
    "    y_pred = model.predict(X_test).round()\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    TPR = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "    print((TPR.round(2))*100)\n",
    "    accuracy_score(y_test, y_pred)\n",
    "    print(accuracy_score)\n",
    "    #return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#y_pred = run_model('accuracy',10)\n",
    "run_model('accuracy',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_model('accuracy',25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_model('Recall',15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_model('TruePositives',15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_model('Precision',15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
